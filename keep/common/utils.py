import hashlib
import httplib2
import logging
import os
from sunburnt import sunburnt
from urlparse import urlparse

from django.conf import settings
from django.contrib.sites.models import Site

logger = logging.getLogger(__name__)

def absolutize_url(local_url):
    '''Convert a local url to an absolute url, with scheme and server name,
    based on the current configured :class:`~django.contrib.sites.models.Site`.
    
    :param local_url: local url to be absolutized, e.g. something generated by
        :meth:`~django.core.urlresolvers.reverse`
    '''
    if local_url.startswith('http'):
        return local_url

    # add scheme and server (i.e., the http://example.com) based
    # on the django Sites infrastructure.
    root = Site.objects.get_current().domain
    # but also add the http:// if necessary, since most sites docs
    # suggest using just the domain name
    if not root.startswith('http'):
        root = 'http://' + root
    return root + local_url

def md5sum(filename):
    '''Calculate and returns an MD5 checksum for the specified file.  Any file
    errors (non-existent file, read error, etc.) are not handled here but should
    be caught where this method is called.

    :param filename: ful path to the file for which a checksum should be calculated
    :returns: hex-digest formatted MD5 checksum as a string
    '''
    # pythonic md5 calculation from Stack Overflow
    # http://stackoverflow.com/questions/1131220/get-md5-hash-of-a-files-without-open-it-in-python
    md5 = hashlib.md5()
    with open(filename,'rb') as f:
        for chunk in iter(lambda: f.read(128*md5.block_size), ''):
             md5.update(chunk)
    return md5.hexdigest()

def solr_interface():
    '''Wrapper function to initialize a
    :class:`sunburnt.SolrInterface` based on django settings and
    evironment.  Uses **SOLR_SERVER_URL** and **SOLR_CA_CERT_PATH** if
    one is set.  Additionally, if an **HTTP_PROXY** is set in the
    environment, it will be configured.
    '''
    http_opts = {}
    if hasattr(settings, 'SOLR_CA_CERT_PATH'):
        http_opts['ca_certs'] = settings.SOLR_CA_CERT_PATH

    # use http proxy if set in ENV
    http_proxy = os.getenv('HTTP_PROXY', None)
    if http_proxy:
        parsed_proxy = urlparse(http_proxy)
        # NOTE: using Squid with httplib2 requires no-tunneling proxy option
        proxy_info = httplib2.ProxyInfo(proxy_type=httplib2.socks.PROXY_TYPE_HTTP_NO_TUNNEL,
                                        proxy_host=parsed_proxy.hostname,
                                        proxy_port=parsed_proxy.port)
        http_opts['proxy_info'] = proxy_info
    http = httplib2.Http(**http_opts)

    solr_opts = {'http_connection': http}
    # since we have the schema available, don't bother requesting it
    # from solr every time we initialize a new connection
    if hasattr(settings, 'SOLR_SCHEMA'):
        solr_opts['schemadoc'] = settings.SOLR_SCHEMA


    solr = sunburnt.SolrInterface(settings.SOLR_SERVER_URL,
                                  **solr_opts)
    return solr




class PaginatedSolrSearch(object):
    # wrapper around sunburnt solrsearch so it can be passed to a django paginator
    # should be a temporary solution - looking into adding this to sunburnt 

    def __init__(self, solrquery):
        self._result_cache = None
        self._count_cache = None
        self.solrquery = solrquery
        
    def count(self):
        # get total count without retrieving any results
        if self._count_cache is None:
            logger.debug('no cached count')
            response = self.solrquery.paginate(rows=0).execute()
            self._count_cache = response.result.numFound
        return self._count_cache

    def __len__(self):
        if self._result_cache is None:
            logger.debug('no cached result (__len__)')
            self._result_cache = self.solrquery.execute()
        return len(self._result_cache)
                
            
    def __getitem__(self, k):
        """Return a single result or slice of results from the query."""
        logger.debug('PaginatedSolrSearch[%s]' % (k,))
        if not isinstance(k, (slice, int, long)):
            raise TypeError
        
        if isinstance(k, slice):
            paginate_opts = {}
            # if start was specified, use it; otherwise retain current start
            if k.start is not None:
                paginate_opts['start'] = int(k.start)
            # if a slice is bigger than available results is requested, cap it at actual max
            if k.stop is None:
                stop = self.count()
            else:
                stop = min(k.stop, self.count())
            paginate_opts['rows'] = stop - k.start
            return PaginatedSolrSearch(self.solrquery.paginate(**paginate_opts))

        # check that index is in range
        # for now, not handling any fancy python indexing
        if k < 0 or k >= self.count():
            raise IndexError

        # index should be relative to currently paginated set
        if self._result_cache is None:
            logger.debug('no cached result (__getitem__)')
            self._result_cache = self.solrquery.execute()
            
        return self._result_cache[k]

